# Ch3 선형회귀
## 기초개념
성적을 변하게 하는 정보 – x(종속변수), x값에 따라 변하는 성적 – y(독립변수)/ x값에 따라 y값이 변한다.     
x값이 1개일 때 = 단순선형회귀, x값이 여러개일 때 = 다중선형회귀    
 
선형회귀 = 최적의 직선(y=ax+b)를 찾아내는 과정    

---
## 최소제곱법
최소제곱법 – x값이 하나일 때 사용    
최소제곱법에서의 기울기 a = (x-x평균)(y-y평균)의 합 / (x-x평균)^2의 합    
최소제곱법에서의 상수 b = y의 평균 – (x의 평균 * 기울기 a)   

---
### 직접 짜본 최소제곱법 코드 실행화면(Colab) – 교재의 코드랑 크게 차이가 없다(div부분 제외하고)
![image](https://user-images.githubusercontent.com/67413252/211447562-d5d4b580-bc00-41f3-a4d1-a5a0c05ef82b.png)

---


## 평균제곱오차(MSE, Mean Squared Error)
x가 여러개일 때, 임의의 선을 그린 후 그걸 평가하여 수정하는 방법 사용    
평균제곱오차(MSE, Mean Squared Error) – 오차 평가법중 가장 많이 사용되는 방법    
기울기가 잘못되었을수록 오차의 값도 커진다. 다만, 오차의 경우 단순히 더할 경우 부호로 인해 정확한 값을 얻지 못할 수 있으므로 실제 값과 원래 값의 차에 제곱을 하여 더해준다. 이를 표본의 개수로 나누어 주면 평균제곱오차가 된다.     

---
### 직접 짜본 코드 실행화면(Colab) - 교재의 코드랑 차이가 있다
![image](https://user-images.githubusercontent.com/67413252/211447735-65659881-8656-4954-8ca1-559d5f8dc561.png)

---

### 교제 코드 Review
중요 부분만 요약
#### data 넣는 부분
```python
sum((i – mx)**2 for i in x)
```
와 같은 코드들에서 for i in x(리스트)는 x라는 리스트 내의 원소 하나씩을 i로 끄집어내서 사용한다.    
```python
data = [[2, 81], [4, 93], [6, 91], [8, 97]]
x = [i[0] for i in data]
y = [i[1] for i in data]
```
따라서 x = [i[0] for i in data]의 경우 차례대로 [2, 81]이라는 원소에서 0번째(2), [4, 93]이라는 원소에서 0번째(4).... 이런식으로 i를 끄집어낸다.   
#### 예측값을 구하는 코드
```python
def predict(x):
    return (fake_a_b[0]*x + fake_a_b[1])
````
MSE 식을 그대로 표현한 코드. 전체 코드상 여기서 y와 y_hat에는 리스트가 들어감.     
y는 실제 값이고, y_hat은 y의 예측값이다.    
*원래 단순 리스트끼리의 연산은 python에서 지원하지 않지만, numpy 라이브러리로 선언된 객체간에는 사칙연산을 지원하므로(데이터분석 스터디 당시 행렬곱, 전치, 사칙연산했던 것처럼) 연산 가능하게 되는 것 같다.    

#### MSE값을 구하는 코드
```python
def mse(y, y_hat):
    return ((y-y_hat) ** 2).mean())
```
위에서 언급했던 이유로 y와 y의 예측값을 np.array로 넣어준다.    
여기서 predict_result는 예측값을 계산해 넣은 리스트이다.    
```python
def mse_val(y, predict_result):
    return mse(np.array(y), np.array(predict_result))
```
