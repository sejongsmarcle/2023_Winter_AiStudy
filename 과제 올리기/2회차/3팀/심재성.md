# 4. 경사하강법

## 2주차

+ 1주차 실습 문제 풀이
<img width="810" alt="image" src="https://user-images.githubusercontent.com/101916929/212807630-e69a0838-4555-4c7e-9832-bb13e94d9935.png">


저번 실습시간 때 이용한 코드로 최소제곱법과 예측값을 구하고, 이번 실습 내용을 공부하면서 그래프를 표현하는 코드를 이용해 실습문제를 풀 수 있었습니다.
 ```python
import numpy as np
import matplotlib.pyplot as plt

# x 값과 y값
x=[1, 6, 12, 18, 24]
y=[10, 30, 35, 50, 75]

# x와 y의 평균값
mx = np.mean(x)
my = np.mean(y)


# 기울기 공식의 분모
divisor = sum([(mx - i)**2 for i in x])

# 기울기 공식의 분자
def top(x, mx, y, my):
    d = 0
    for i in range(len(x)):
        d += (x[i] - mx) * (y[i] - my)
    return d
dividend = top(x, mx, y, my)


# 기울기와 y 절편 구하기
a = dividend / divisor
b = my - (mx*a)

# 데이터 정렬하기
x_data = np.array(x)
y_data = np.array(y)

#예측값구하기
y_hat = a * x_data + b

plt.figure(figsize=(8,5))
plt.scatter(x, y)
plt.plot([min(x_data), max(x_data)], [min(y_hat), max(y_hat)])
plt.show()

print("식 = %.02f,x + %.02f" %(a,b))
 ```
 <img width="368" alt="image" src="https://user-images.githubusercontent.com/101916929/212808118-7a3cfa26-4cde-4d3e-b54b-5eae14f22fbb.png">

***

+ 경사하강법

경사하강법은 미분 기울기를 이용하여 그래프에서 오차를 비교하여 가장 작은 방향으로 이동시키는 방법이다

<img width="196" alt="image" src="https://user-images.githubusercontent.com/101916929/212808816-fc1a312a-5597-4e49-ab62-4c8632100562.png">

위와 같은 형태로 

a1에서 미분을 구한다

구해진 기울기의 반대 방향으로 얼마간 이동시킨 a2를 미분을 구한다.

위에서 구한 미분 값이 0이 아니면 위 과정을 반복한다.

***

+ 학습률

경사하강법을 설명할때 a1에서 a2로 넘어갈때 기울기의 반대 방향으로 얼마간 이동한다는 설명이 있었는데

학습률이 여기서 말하는 '얼마간'이다.

학습률을 잘 설정하는 것이 최적화 방법중 하나이다.

***

+ 코딩으로 확인하는 경사 하강법

yi =axi +b x값에 따라 y의 예측값이 바뀌고 이 값을 미분하여 a와 b값을 구할 수 있다.

<img width="224" alt="image" src="https://user-images.githubusercontent.com/101916929/212810591-657673f4-0d1c-4ea3-a1b1-0838b9e2e725.png">

그래서 위 식에서 a와 b를 편미분하여 구할 수 있다.

<img width="283" alt="image" src="https://user-images.githubusercontent.com/101916929/212810683-ccac57d5-fa17-473a-aa3e-63df76a55ba3.png">

위 내용을 코드화 하면
``` python

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#공부시간 X와 성적 Y의 리스트를 만듭니다.
data = [[2, 81], [4, 93], [6, 91], [8, 97]]
x = [i[0] for i in data]
y = [i[1] for i in data]

#그래프로 나타내 봅니다.
plt.figure(figsize=(8,5))
plt.scatter(x, y)
plt.show()

#리스트로 되어 있는 x와 y값을 넘파이 배열로 바꾸어 줍니다.(인덱스를 주어 하나씩 불러와 계산이 가능해 지도록 하기 위함입니다.)
x_data = np.array(x)
y_data = np.array(y)

# 기울기 a와 절편 b의 값을 초기화 합니다.
a = 0
b = 0

#학습률을 정합니다.
lr = 0.03 

#몇 번 반복될지를 설정합니다.
epochs = 2001 

#경사 하강법을 시작합니다.
for i in range(epochs): # epoch 수 만큼 반복
    y_hat = a * x_data + b  #y를 구하는 식을 세웁니다
    error = y_data - y_hat  #오차를 구하는 식입니다.
    a_diff = -(2/len(x_data)) * sum(x_data * (error)) # 오차함수를 a로 미분한 값입니다. 
    b_diff = -(2/len(x_data)) * sum(error)  # 오차함수를 b로 미분한 값입니다. 
    a = a - lr * a_diff  # 학습률을 곱해 기존의 a값을 업데이트합니다.
    b = b - lr * b_diff  # 학습률을 곱해 기존의 b값을 업데이트합니다.
    if i % 100 == 0:    # 100번 반복될 때마다 현재의 a값, b값을 출력합니다.
        print("epoch=%.f, 기울기=%.04f, 절편=%.04f" % (i, a, b))

# 앞서 구한 기울기와 절편을 이용해 그래프를 그려 봅니다.
y_pred = a * x_data + b



plt.scatter(x, y)
plt.plot([min(x_data), max(x_data)], [min(y_pred), max(y_pred)])
plt.show()
```

<img width="292" alt="image" src="https://user-images.githubusercontent.com/101916929/212811188-7af97964-95e4-4ce8-8823-873a0d28a7ac.png">


***

+ 다중 선형 회귀 

더 정확한 예측값을 얻기 위해서는 예측값을 결정하는 요인이 많아져야한다.
예측값이 y라면 x값이 많을 수록..? 많으면 더 정확한 예측값을 얻을 수 있다.

다중 선형회귀를 바로 코딩으로 확인하자면

```python

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

#공부시간 X와 성적 Y의 리스트를 만듭니다.
data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]
x1 = [i[0] for i in data]
x2 = [i[1] for i in data]
y = [i[2] for i in data]

#그래프로 확인해 봅니다.
ax = plt.axes(projection='3d')
ax.set_xlabel('study_hours')
ax.set_ylabel('private_class')
ax.set_zlabel('Score')
ax.dist = 11 
ax.scatter(x1, x2, y)
plt.show()





#리스트로 되어 있는 x와 y값을 넘파이 배열로 바꾸어 줍니다.(인덱스를 주어 하나씩 불러와 계산이 가능해 지도록 하기 위함입니다.)
x1_data = np.array(x1)
x2_data = np.array(x2)
y_data = np.array(y)

# 기울기 a와 절편 b의 값을 초기화 합니다.
a1 = 0
a2 = 0
b = 0

#학습률을 정합니다.
lr = 0.02 

#몇 번 반복될지를 설정합니다.(0부터 세므로 원하는 반복 횟수에 +1을 해 주어야 합니다.)
epochs = 2001 

#경사 하강법을 시작합니다.
for i in range(epochs): # epoch 수 만큼 반복
    y_pred = a1 * x1_data + a2 * x2_data + b  #y를 구하는 식을 세웁니다
    error = y_data - y_pred  #오차를 구하는 식입니다.
    a1_diff = -(2/len(x1_data)) * sum(x1_data * (error)) # 오차함수를 a1로 미분한 값입니다. 
    a2_diff = -(2/len(x2_data)) * sum(x2_data * (error)) # 오차함수를 a2로 미분한 값입니다. 
    b_new = -(2/len(x1_data)) * sum(y_data - y_pred)  # 오차함수를 b로 미분한 값입니다. 
    a1 = a1 - lr * a1_diff  # 학습률을 곱해 기존의 a1값을 업데이트합니다.
    a2 = a2 - lr * a2_diff  # 학습률을 곱해 기존의 a2값을 업데이트합니다.
    b = b - lr * b_new  # 학습률을 곱해 기존의 b값을 업데이트합니다.
    if i % 100 == 0:    # 100번 반복될 때마다 현재의 a1, a2, b값을 출력합니다.
        print("epoch=%.f, 기울기1=%.04f, 기울기2=%.04f, 절편=%.04f" % (i, a1, a2, b))




import statsmodels.api as statm
import statsmodels.formula.api as statfa
#from matplotlib.pyplot import figure

X = [i[0:2] for i in data]
y = [i[2] for i in data]

X_1=statm.add_constant(X)
results=statm.OLS(y,X_1).fit()

hour_class=pd.DataFrame(X,columns=['study_hours','private_class'])
hour_class['Score']=pd.Series(y)

model = statfa.ols(formula='Score ~ study_hours + private_class', data=hour_class)

results_formula = model.fit()

a, b = np.meshgrid(np.linspace(hour_class.study_hours.min(),hour_class.study_hours.max(),100),
                   np.linspace(hour_class.private_class.min(),hour_class.private_class.max(),100))

X_ax = pd.DataFrame({'study_hours': a.ravel(), 'private_class': b.ravel()})
fittedY=results_formula.predict(exog=X_ax)

fig = plt.figure()
graph = fig.add_subplot(111, projection='3d')

graph.scatter(hour_class['study_hours'],hour_class['private_class'],hour_class['Score'],
              c='blue',marker='o', alpha=1)
graph.plot_surface(a,b,fittedY.values.reshape(a.shape),
                   rstride=1, cstride=1, color='none', alpha=0.4)
graph.set_xlabel('study hours')
graph.set_ylabel('private class')
graph.set_zlabel('Score')
graph.dist = 11

plt.show()

```

<img width="285" alt="image" src="https://user-images.githubusercontent.com/101916929/212811574-6630d27c-8b67-41f9-9785-f404b0a35c0a.png">
