# 10,11장 실습문제 풀이
----
https://colab.research.google.com/drive/1BP0LTfTI0ELOSVQEHHOmwH5hIxbiEpqR#scrollTo=etbjicdyPPuc


# 13장: 과적합 피하기
-------
과적합이란 모델이 학습 데이터셋 안에서는 일정 수준 이상의 예측 정확도를 보이지만, 새로운 데이터에 적용하면 잘 맞지 않는 것을 말한다. 
![image](https://user-images.githubusercontent.com/94752167/218728759-a2d51abe-fb59-4360-9910-cdbbee5b2dea.png)    
위 그림에서 빨간 색은 주어진 샘플에만 정확히 맞고, 새로운 데이터에 적용하면 정확히 두 그룹으로 나누지 못한다.   
과적합은 층이 너무 많을 때도 발생하고, 테스트셋과 학습셋이 중복될 때 생기기도 한다.   
과적합을 피하기 위해서는 학습 데이터셋과 테스트 데이터셋을 구분하는 법이 있다.    
![image](https://user-images.githubusercontent.com/94752167/218729539-8049fac9-6210-4cb7-ada0-9f4ec1a05370.png)    
위 그림처럼 학습 데이터로 학습하여 모델을 생성하고, 이후 테스트 데이터로 모델의 성능을 평가한다.    
학습 데이터로 평가를 하게 되면, 실행 횟수가 늘을수록 정확도가 개선되지만, 과적합이 일어날 수도 있다.   
![image](https://user-images.githubusercontent.com/94752167/218730043-70d5413c-1469-43d0-8665-aff62cafdccf.png)    
위 그래프와 같이 학습을 진행해도 테스트 결과가 더 이상 좋아지지 않는 지점에서 학습을 멈춰야 한다. 
사이킷런 라이브러리의 train_test_split()함수를 사용하여 정해진 비율로 학습 데이터셋과 테스트 데이터셋을 분리할 수 있다. (ex) train_test_split(x,y,test_size=0.3,random_state=seed)   

학습을 끝낸 수 테스트 결과가 좋으면 이 모델을 저장하여 새로운 데이터에 사용할 수 있다.   
![image](https://user-images.githubusercontent.com/94752167/218730930-366d2930-2d21-433f-859e-ebff3bedfe4f.png)    
이 모델을 다음과 같이 불러올 수 있다.    
![image](https://user-images.githubusercontent.com/94752167/218731035-fe3a0fce-b34e-4008-bc88-3085dcb1721f.png)     

- k겹 교차검증
학습 데이터셋과 테스트 데이터셋으로 나눌 경우 테스트할 데이터셋이 부족한 문제가 생긴다. 이 문제를 k겹 교차 검증으로 해결할 수 있다. k겹 교차검증은 쉽게 말해 팀을 나눠 어떨 때에는 학습에, 다를 때에는 테스트에 사용하는 것이다. 정확히 표현하면 데이터셋을 여러 개로 나누어 하나씩 테스트셋으로 사용하고 나머지는 모두 학습 데이터셋으로 사용하는 것이다. 이 방법으로 모든 데이터를 테스트셋으로 사용할 수 있다.   
![image](https://user-images.githubusercontent.com/94752167/218734933-25e52bfe-f8a8-498f-9eb0-7cc8470278ed.png)   

사이킷런에서 StratifiedKFold()함수를 사용하여 데이터를 원하는 숫자만큼 학습셋과 테스트셋으로 쪼개 사용할 수 있다.   
![image](https://user-images.githubusercontent.com/94752167/218735177-dc371143-1bed-4194-b108-4587c004c9b1.png)    
위 그림에서는 10개로 파일 쪼갠 10겹 교차검증을 실시했다.    
![image](https://user-images.githubusercontent.com/94752167/218735430-f34374ba-f2dc-446c-baff-e82080a02258.png)    
위 그림에서는 모델을 만들고 실행하는 부분을 for구분으로 묶어 n_fold만큼 반복되게 했다.    
train 데이터로 학습시킨 것을 볼 수 있다.    
![image](https://user-images.githubusercontent.com/94752167/218735935-339bc7dd-d6ec-4eb5-bda7-4d068dcb2b57.png)     
정확도를 test데이터로 평가하여 accuracy 배열로 나타낼 수 있다.    

# 14장: 베스트 모델 만들기
--------
이 장에서는 레드와이노가 화이트와인을 구분하는 실험을 진행한다.    
![image](https://user-images.githubusercontent.com/94752167/218736686-88f7aa61-1465-4ed1-aeed-f0791b59eda4.png)   
df_pre 공간에 데이터를 불러 오고 sample함수로 원본 데이터의 몇 %를 사용할지를 지정한다. frac가 1이면 100%을 사용하며 frac가 0.5일 경우는 50%를 사용한다.    
이 데이터에는 13개의 속성이 있으며, 0~11번째의 속성을 통해 마지막 13번째 클랙스를 맞추는 과제이다.   
![image](https://user-images.githubusercontent.com/94752167/218737383-01325a72-d924-49fe-b75c-e66e47b069c6.png)    
따라서, x,y값을 위와 같이 정할 수 있다.    
딥러닝은 4개의 은닉층을 만들고, 이항분류문제이므로 binary_crossentropy함수를 사용하고, 최적화함수로는 adam을 사용한다.    

- 모델 업데이트하기
모델을 에포크마다 모델의 정확도와 함께 기록하면서 저장할 수 있다. 
![image](https://user-images.githubusercontent.com/94752167/218737917-aef43bbb-b2d9-4f71-8e60-f467fcfce404.png)    
위 코드에서는 모델을 저장할 디렉터리를 만ㄷ르고 에포크 횟수와 테스트셋 오차 값을 이요해 파일 이름을 만들었다.    
![image](https://user-images.githubusercontent.com/94752167/218738145-56b7a93c-a3da-45ea-af8a-8344d6d655c9.png)    
모델을 저장하기 위해 케라스의 콜백 함수중 ModelCheckpoint()함수를 불러온다.    
![image](https://user-images.githubusercontent.com/94752167/218738323-ff770102-9f77-44ab-9b46-b861e406619c.png)   
checkpointer 별수를 만들어 값을 지정한다. modelpath는 모델이 저장될 곳을 의미하며, monitor는 케라스 내부에 기록할 테스트 오차를 의미한다. verbose는 1일 때는 함수의 진행 상황이 출력되도록 하고 0이면 출력되지 않는다.    
![image](https://user-images.githubusercontent.com/94752167/218738998-ab6cf7c1-5a31-414f-9c95-6e562d861a96.png)    
모델을 학습할 때만다 checkpoint값을 받아 callbacks에 입력하여 저장한다.    
![image](https://user-images.githubusercontent.com/94752167/218739233-2c832adf-c3d1-4bd8-97ea-e2a975797b52.png)    
save_best_only를 true로 설정하면 모델이 나아질 경우에만 저장하도록 할 수 있다.    

- 그래프로 확인하기     
앞에서 말했듯이 에포크를 적당히 지정해야 하며, 너무 만힝 학습을 반복하면 과적합의 문제가 있고 너무 적어도 학습 결과가 좋지 않다. 따라서, 모델의 학습 시간에 따른 정확도와 테스트 결과를 그래프로 확인 하는 방법이 있다.    
![image](https://user-images.githubusercontent.com/94752167/218739731-4d88a68a-3b96-407c-9723-4da3fe7aab55.png)     
위의 코드와 같이 샘플의 15%를 불러왔다. 또한, 에포크를 3500, 배치 크기를 500으로 하였다.    
![image](https://user-images.githubusercontent.com/94752167/218740316-13b56f79-308a-4250-9168-714e5bbb045b.png)    
위와 같이 y_vloss에 오차 값을 저장하고 y_acc에 정확도와 값을 저장한다.    
![image](https://user-images.githubusercontent.com/94752167/218740621-77479487-79f6-4797-9c81-1be67921fc16.png)    
x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시한다.    
![image](https://user-images.githubusercontent.com/94752167/218740799-b5eb6b1d-c503-4fd8-8e51-2aada2c7d527.png)   
결과는 위와 같다.    
![image](https://user-images.githubusercontent.com/94752167/218740883-55a9df6d-1677-49dc-bfe2-5f59498f93bb.png)   
이것을 단순하게 표현하면 위의 그림과 같다. 학습셋의 정확도는 시간이 흐를수록 좋아지지만, 테스트셋의 결과값은 어느 정도 이상이 되면 더 나아지지 않는 것을 확인할 수 있다.    
























