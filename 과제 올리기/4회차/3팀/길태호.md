# 6장. 퍼셉트론
--------------
인간의 뇌는 여러 뉴런으로 이루어져 있으며, 뉴런과 뉴런이 연결되어 자신의 역할을 수행한다.    
이처럼, 여러층의 퍼셉트론을 서로 연결시키고 복잡하게 조합하여 입력 값에 대한 판단을 하는 것이 신경망의 기본 구조이다.    
뉴런에서 전위가 임계 값을 넘겨야 다음 뉴런으로 신호를 전달하듯이,     
로지스틱회귀에서 활성화 함수의 일정 수준을 넘으면 참을, 그렇지 않으면 거짓을 내보낸다.    
![image](https://user-images.githubusercontent.com/94752167/215746216-98b0a53b-796d-49b9-9a7f-d21baa6c0a94.png)
     
신경망을 이루는 가장 중요한 기본 단위는 퍼셉트론이다.    
퍼셉트론은 입력값과 활성화 함수를 사용해 출력 값을 다음으로 넘기는 가장 작은 신경망의 단위이다.   

## 6.1 가중치, 가중합, 바이어스, 활성화함수
-------------
전에 표현했던 y=ax+b에서 a는 기울기를, b는 y절편을 의미했다. 이를 딥러닝에서는 y=wx+b로 표현할 수 있다.     
y=wx+b에서 w는 가중치를, b는 바이어스를 의미한다.    
이 y=wx+b는 가중합이라고 부른다.    
이 가중합의 결과를 놓고 1 또는 0을 판단하는 함수를 활성화함수라고 부른다.    

## 6.2 퍼셉트론의 과제
------------

사람의 뉴런과 마찬가지로 퍼셉트론은 여러개가 필요하다.    
![image](https://user-images.githubusercontent.com/94752167/215747867-b0818fcc-4a44-4f75-b6b8-1f912c3d27d6.png)        

위 그림에서 어떻게 선을 긋더라도 검은색과 흰색 점으로 분류할 수 없다.

## 6.3 XOR 문제
-----------
위와 같은 문제는 XOR 문제이다.    
XOR문제는 논리 회로에 등장하는 개념으로, x1과 x2가 하나는 1이고 하나는 0인 경우에 결과값이 1인 회로이다.     
![image](https://user-images.githubusercontent.com/94752167/215748464-b3886690-689a-465a-8ae3-cae039b5b5b6.png)     

AND 게이트와 OR 게이트와 달리, XOR 게이트에서는 선을 그어 검은 점을 구별할 수 없다.     
이러한 문제는 다층 퍼셉트론으로 해결하게 된다.    

# 7. 다층 퍼셉트론
-----------------

위에서 말한 XOR 문제를 해결하기 위해서는 종이를 휘어야 한다.   
즉, 좌표 평면 자체에 변화를 주어야 한다.    
![image](https://user-images.githubusercontent.com/94752167/215749336-b5fa082a-5f8c-48ce-8f53-40917b602e0c.png)    

따라서, xor 문제를 해결하기 위해서는 두 개의 퍼셉트론을 한번에 계산할 수 있어야 하며, 이를 위해 숨어있는 층인 은닉층을 만들어야 한다.  

![image](https://user-images.githubusercontent.com/94752167/215749560-72a9afc2-86cc-42c1-b618-4d84ff4e3fbd.png)    

은닉층은 좌표평면을 외곡시키는 결과를 가져온다.    

![image](https://user-images.githubusercontent.com/94752167/215749721-36365131-de6b-4ccd-85a1-892ac0efea66.png)    

위와 같이 입력값을 놓고 파란색과 빨간색을 구분할 때, 은닉층을 만들어 공간을 왜곡시키면, 두 영역을 가로지르는 선이 직선으로 바뀐다.    

## 7.1 다층 퍼셉트론 설계
-----------
다층 퍼셉트론이 입력층과 출력층 사이에 숨어있는 은닉층을 만드는 과정은 아래와 같다.     
![image](https://user-images.githubusercontent.com/94752167/215751002-cefc5c6e-e239-44e2-b474-5fbbf9327e25.png)     

은닉층으로 가중치 w와 바이어스 b 값을 보내고 은닉층에 모인 값이 시그모이드 함수를 통해 최종값으로 결과를 보낸다. 이후 시그모이드 함수를 이용해 최종값으로 결과를 보낸다. 은닉층에 모이는 중간 정거장을 노드라고 한다. 이 노드의 값은 각각 단일 퍼셉트론의 값과 같다.    
![image](https://user-images.githubusercontent.com/94752167/215752461-e7248275-9834-4e50-81fc-5136dfa1c4f8.png)     

이 식의 결과값이 출력층으로 보내지고, 이 두 결과값을 다시 가중치와 바이어스를 처리하고 시그모이드 함수를 거치는 과정을 가진다. 
![image](https://user-images.githubusercontent.com/94752167/215752632-ac01f68d-b37f-4382-a180-d75c0948b369.png)    

각각의 가중치와 바이어스의 값은 아래와 같다.   

![image](https://user-images.githubusercontent.com/94752167/215752928-390b564e-b0d3-4316-81f9-3e7726364fa4.png)     

## 7.2 XOR 문제의 해결
-------
위에서 말한 다층 퍼셉트론을 통해 xor 문제가 해결되는지 확인해보자.   

![image](https://user-images.githubusercontent.com/94752167/215753493-c0674be7-fbdf-439a-a4e3-cf76445b4293.png)    

각각의 가중치와 바이어스는 위와 같다.   

![image](https://user-images.githubusercontent.com/94752167/215753582-70438382-7714-44a0-9825-dc217f254900.png)    

도식은 위와 같다.    

![image](https://user-images.githubusercontent.com/94752167/215753711-f9624971-0543-4b7d-9816-242d9a93793e.png)    

그 결과값은 위와 같다. 은닉층을 통한 다층 퍼셉트론으로 XOR 문제를 해결한 것을 볼 수 있다.    


## 7.3 코딩으로  XOR 문제 해결하기
---------

위의 표를 보면 n1은 모드 1일 경우 0을, 이외의 경우에는 1을 출력하는 NAND 게이트이다.    
또한, n2는 OR 게이트이다.    
따라서, 두 게이트를 각각 작동시키고 두 값에 대해 AND 게이트를 수행한 값이 결과값 Y이다.   

![image](https://user-images.githubusercontent.com/94752167/215754629-67b9d9c7-8321-4d18-a5bf-ee7ce97efa4b.png)     
가중치와 바이어스는 위와 같다.   

![image](https://user-images.githubusercontent.com/94752167/215754772-a8f1ba8f-283a-465c-a98e-c433b4d185e5.png)    

퍼셉트론은 0과 1 중에서 값을 출력하게 설정한다.   
![image](https://user-images.githubusercontent.com/94752167/215754950-8fe33efe-adb1-4356-912b-31860dd1455d.png)    
![image](https://user-images.githubusercontent.com/94752167/215754986-654e4aee-efb6-4420-966a-c869ae98edc2.png)   

각 게이트의 정의에 따라 NAND,OR,AND,XOR 게이트를 만드면 위와 같다.   

![image](https://user-images.githubusercontent.com/94752167/215755154-ea21cd22-3498-4e01-961c-ab62f5ba8341.png)    

마지막으로 X1과 X2의 값을 대입해 가며 최종값을 출력하면 위와 같다.   

이를 모두 정리하면 아래와 같다.   

https://colab.research.google.com/drive/1Fvs7Rfig3MoFiIEXDZHd4efS_MKecxI5#scrollTo=L6v_OcXNxJvU

# 8장. 오차 역전파
----------

신경망 내부의 가중치는 오차 역전파 방법을 사용해 수정한다. 오차 역전파는 경사하강법의 확장 개념이다.    

## 8.1 오차 역전파의 개념
----------
가중치와 바이어스를 구하기 위해서는 오차 역전파를 사용한다. 오차 역전파는 최적화의 계산 방향이 출력층에서 시작해 앞으로 진행된다. 이러한 다층 퍼셉트론에서의 최적화 과정이 오차 역전파이다.     
![image](https://user-images.githubusercontent.com/94752167/215764175-b788f2b7-9084-46a5-94be-a2808bc34a72.png)      

오차 역전파의 과정은 앞에서의 경사하강법과 비슷하다. 다만, 경사하강법은 입력과 출력이 하나인 단일 퍼셉트론일 경우에 사용했지만, 오차 역전파는 다층 퍼셉트론의 경우에 사용한다. 오차를 구해 이를 토해로 앞선 가중치를 차례로 거슬러 올라가며 조정해 간다. 이라헌 구동 방식은 아래와 같다.     

![image](https://user-images.githubusercontent.com/94752167/215764670-bb2f7a99-acca-42b6-b26a-c31ff74adb85.png)    

오차가 작아지는 방향으로 업데이트한다는 의미는 미분 값이 0에 가까워지는 방향으로 나아간다는 의미이다.   
다시 말하면, 가중치에서 기울기를 뺐을 때 변화가 없어야 한다.   
식으로 표현하면 아래와 같다.   
![image](https://user-images.githubusercontent.com/94752167/215764985-cca07263-24be-43bc-9137-34a1f8129927.png)    

## 8.2 코딩으로 확인하는 오차 역전파
-----------
오차 역전파의 경우 경사하강법과 달리 가중치를 몰라도 가능하다. 입력된 실제 값과 다층 퍼셉트론의 계산 결과를 비교하여 가중치를 역전파 방식으로 수정해나간다.    

![image](https://user-images.githubusercontent.com/94752167/215765358-fdc342d6-3692-4a53-b5a5-848d981e6aa8.png)    

![image](https://user-images.githubusercontent.com/94752167/215765523-6a7406b0-e9ba-4a09-9831-455da9eaf86b.png)   

우리는 이러한 신경망이 구현되어 있는 케라스, 텐서플로와 같은 딥러닝 라이브러리를 사용한다.   

# 9장. 신경망에서 딥러닝으로
------------
다층 퍼셉트론이 오차 역전파를 만나 신경망이 되었고, 신경망은 XOR 문제를 해결하였다. 하지만, 결과가 기대만큼 좋지 못했다. 9장에서는 그 이유와 해결방법에 대해 알아본다.   

## 9.1 기울기 소실 문제와 활성화 함수
----------
오차 역전파는 출력층으로부터 하나씩 앞으로 되돌아가며 각 층의 가중치를 수정한다.    
가중치를 수정하는 과정에서 미분값인 기울기를 구하는데, 은닉층이 늘어나게 되면 이 기울기의 값이 점점 작아져서 맨 처음 층까지 전달되지 않는 기울기 소실 문제가 발생한다.    

![image](https://user-images.githubusercontent.com/94752167/215767216-b6f4632d-cad5-4c55-bca4-a53de08ea597.png)    

그 이유는 시그모이드 함수를 미분하면 최대치가 0.3이기 때문이다. 1보다 작기 때문에 계속 곱하다보면 0에 가까워지고 여러 층을 거치면 기울기가 사라져 가중치를 수정하기 어려워진다.   

![image](https://user-images.githubusercontent.com/94752167/215767481-926177f4-10a5-4625-9360-49f6561c632a.png)    

이를 대체하기 위해 여러 함수가 있다.   

![image](https://user-images.githubusercontent.com/94752167/215769001-bb72e0dd-9a4f-4362-bf0b-5529f94c387c.png)    
하이퍼볼릭 탄젠트는 미분한 값의 범위가 함께 확장되지만, 여전히 1보다 작은 값이 존재하므로 기울기 소실 문제는 사라지지 않는다.      
렐룰 함수는 현재 가장 많이 사용되며, x가 0보다 작은 경우에는 0으로, 0보다 큰 값은 x를 그대로 사용한다. 미분할 경우, 0보다 크기만 하면 미분값이 1이 된다. 따라서 여러 은닉층을 거치며 곱해지더라도 맨 처음 층까지 사라지지 않고 남아있는다.      
소프트플러스 함수는 렐루가 0이 되는 순간을 완화한 함수이다.     
이외에 다량한 함수가 개발중에 있다.    

## 9.2 속도와 정확도 문제를 해결하는 고급 경사 하강법
------------
앞에서 배운 경사 하강법은 정확하게 가중치를 찾아가지만, 한 번 업데이트할 때마다 전체 데이터를 미분해야 하므로 계산량이 매우 많다. 이러한 경사 하강법의 단점을 보완한 고급 경사하강법이 있다.   
- 확률적 경사 하강법    
이는 전체 데이터를 사용하지 않고 랜덤하게 추출한 일부 데이터를 사용한다. 일부 데이터를 사용하므로 더 빨리 자주 업데이트를 할 수 있다.    

![image](https://user-images.githubusercontent.com/94752167/215771131-6516d959-87ed-4a3d-bad1-5541987a5829.png)     

위의 그림과 같이 랜덤한 일부 데이터를 사용하는 만큼 확률적 경사하강법은 진폭이 크고 불안정해보이지만, 속도가 빠르고 최적해에 근사한 값을 찾아낸다는 장점이 있다.   

-  모맨텀   
모맨텀은 광성, 탄력, 가속도란 뜻이다. 모멘텀은 경사하강법과 마찬가기로 매번 기울기를 구하지만, 오차를 수정하기 전에 수정 값과 같은 방향으로 일정한 비율만 수정되게 한다. 따라서, 수정 방향이 양수에서 음수로 지그재그하는 현상이 줄어들고 이전 이동 값을 고려해 일정 비율만큼만 다음 값을 결정하므로 관성의 효과를 낼 수 있다.     

![image](https://user-images.githubusercontent.com/94752167/215771867-0654db2a-10f8-4d31-a8e8-fade9bc62495.png)    

이외에도 다양한 방법이 있다. 각 방법이 개발된 순서대로 정리하면 아래와 같다. 먼저 나온 방법의 단점을 보안하여 다음 방법이 나오므로 나중에 나온 방법의 성과가 더 좋다. 가장 밑에 있는 아담은 현재 가장 많이 사용하는 고급 경사 하강법이다.    

![image](https://user-images.githubusercontent.com/94752167/215772241-9c7371a1-7bb6-4781-b884-3c3579a0c62b.png)      
![image](https://user-images.githubusercontent.com/94752167/215772283-8f86a5e9-a32c-4586-b608-76c3bbaab3a7.png)    



 






























