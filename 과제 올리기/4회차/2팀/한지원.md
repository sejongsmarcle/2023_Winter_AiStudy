# 지난 주차 실습문제
https://colab.research.google.com/drive/1_B0ZpvHvWfMefCZJAWqiNjU7KRturgXo?usp=sharing

# Ch 6. 퍼셉트론
- 신경망을 이루는 가장 중요한 기본 단위는 퍼셉트론 이다. 
- 퍼셉트론은 입력 값과 활성화 함수를 사용해 출력 값을 다음으로 넘기는 가장 작은 신경망 단위이다.

## 1. 가중치, 가중합, 바이어스, 활성화 함수
- 가중치: y=ax+b에서 기울기에 해당하는 a를 가중치를 의미하는 w(weight)로 표기
- 바이어스: y=ax+b에서 y절편에 해당하는 b를 가중치를 의미하는 b(bias)로 표기
- 가중합: 입력값 x와 가중치 w의 곱을 모두 더한 다음 바이어스 b를 더한 값.
- 활성화 함수: 가중합의 결과를 놓고 1 또는 0을 출력해서 다음으로 보내고, 여기서 0과 1을 판단하는 함수가 활성화 함수이다.

## 2. 퍼셉트론의 과제
- 선형 회귀와 로지스틱 회귀처럼 머신러닝은 결국 선이나 2차원 평면을 그리는 작업이다.
- 퍼셉트론 역시 선을 긋는 작업이다.
- 하지만 경우에 따라 선을 아무리 그어도 해결되지 않는 상황이 있다.

## 3. XOR 문제
- XOR의 경우 하나의 선을 그어 결과값이 1인 값을 구별할 수 없었다.

# Ch 7. 다층 퍼셉트론
- XOR 문제를 해결하기 위해서 우리는 두 개의 퍼셉트론을 한 번에 계산할 수 있어야 한다. 
- 이를 가능하게 하려면 숨어있는 층, 즉 은닉층(hidden layer) 을 만들면 된다.
- 은닉층을 만들어 공간을 왜곡하면 두 영역을 가로지르는 선이 직선으로 바뀐다.

## 1. 다층 퍼셉트론의 설계
- 단일 퍼셉트론의 값   
![image](https://user-images.githubusercontent.com/101804119/215695941-336cce35-2b83-43c5-85d1-f6cb8e0ef0ce.png)
- 출력층으로 보내진 값   
![image](https://user-images.githubusercontent.com/101804119/215696072-e41ed9e1-9418-499d-8fe8-34bbbd337e27.png)
- 가중치와 바이어스 값   
![image](https://user-images.githubusercontent.com/101804119/215696173-26fac291-b4d3-4133-8e0a-76e5b5ded13d.png)

## 2. XOR 문제의 해결
- n1, n2, y를 구하는 공식에 차례로 대입하여 구한다.
- 숨어있는 두 개의 노드를 둔 다층 퍼셉트론을 통해 XOR 문제를 해결한다.

## 3. 코딩으로 XOR 문제 해결하기
``` python
import numpy as np

# 가중치와 바이어스 설정
w11 = np.array([-2, -2])
w12 = np.array([2, 2])
w2 = np.array([1, 1])
b1 = 3
b2 = -1
b3 = -1

# 퍼셉트론
def MLP(x, w, b):
    y = np.sum(w * x) + b
    if y <= 0:
        return 0
    else:
        return 1

# NAND 게이트
def NAND(x1, x2):
    return MLP(np.array([x1, x2]), w11, b1)

# OR 게이트
def OR(x1, x2):
    return MLP(np.array([x1, x2]), w12, b2)

# AND 게이트
def AND(x1, x2):
    return MLP(np.array([x1, x2]), w2, b3)

# XOR 게이트
def XOR(x1, x2):
    return AND(NAND(x1, x2), OR(x1, x2))

# x1, x2 값을 번갈아 대입하여 최종 값 출력
if __name__ == '__main__':
    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:
        y = XOR(x[0], x[1])
        print("입력 값: " + str(x) + "출력 값: " + str(y))
```

# Ch 8. 오차 역전파
## 1. 오차 역전파의 개념
- 다층 퍼셉트론에서의 최적화 과정을 오차 역전파라고 부른다.
- 오차 역전파 구동 방식
  - 임의의 초기 가중치(W)를 준 뒤 결과(yout)를 계산한다.
  - 계산 결과와 우리가 원하는 값 사이의 오차를 구한다.
  - 경사 하강법을 이용해 바로 앞 가중치를 오차가 작아지는 방향으로 업데이트한다.
  - 위 과정을 더이상 오차가 줄어들지 않을 때까지 반복한다.

## 2. 코딩으로 확인하는 오차 역전파
- 1. 환경 변수 지정: 환경 변수에는 입력 값과 타깃 결괏값이 포함된 데이터셋, 학습률 등이 포함됩니다. 
또, 활성화 함수와 가중치 등도 선언되어야 합니다.
- 2. 신경망 실행: 초깃값을 입력하여 활성화 함수와 가중치를 거쳐 결괏값이 나오게 합니다
- 3. 결과를 실제 값 과 비교: 오차를 측정합니다.
- 4. 역전파 실행: 출력층과 은닉츠으이 가중치를 수정합니다.
- 5. 결과 출력

# Ch 9. 신경망에서 딥러닝으로
## 1. 기울기 소실 문제와 활성화 함수
- 층이 늘어나면서 역전파를 통해 전달되는 기울기의 값이 점점 작아져 맨 처음 층까지 전달되지 않는 기울기 소실 문제가 발생한다.
- 이를 해결하고자 활성화 함수를 시그모이드가 아닌 여러 함수로 대체하기 시작했다.
- 렐루를 변형한 함수와 같은 좀 더 나은 활성화 함수를 만들기 위한 노력이 이어지고 있다.

## 2. 속도와 정확도 문제를 해결하는 고급 경사 하강법
- 확률적 경사 하강법: 전체 데이터를 사용하는 것이 아니라 랜덤하게 추출한 일부 데이터를 사용하는 방법
- 모멘텀: 경사 하강법에 탄력을 더해 주는 방법
- 그외 네스테로프 모멘텀, 아다그라드, 알엠에스프롭 등이 존재한다.
