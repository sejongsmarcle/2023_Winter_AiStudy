16장 CNN
===

* 데이터 전처리

이미지는 픽셀로 이루어져 있습니다. 각 픽셀은 밝기 정도에 따라 등급을 매긴다

1~255까지의 등급으로 이루어진 숫자 중 하나로 긴 행렬로 이루어진 하나의 집합으로 변환됩니다.


***

MNIST 손글씨 인식하기 : 데이터 전처리
```python
#-*- coding: utf-8 -*-

from keras.datasets import mnist
from keras.utils import np_utils

import numpy
import sys
import tensorflow as tf

# seed 값 설정
seed = 0
numpy.random.seed(seed)
tf.random.set_seed(3)

# MNIST데이터셋 불러오기
(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()

print("학습셋 이미지 수 : %d 개" % (X_train.shape[0]))
print("테스트셋 이미지 수 : %d 개" % (X_test.shape[0]))

# 그래프로 확인
import matplotlib.pyplot as plt
plt.imshow(X_train[0], cmap='Greys')
plt.show()

# 코드로 확인
for x in X_train[0]:
    for i in x:
        sys.stdout.write('%d\t' % i)
    sys.stdout.write('\n')

# 차원 변환 과정
X_train = X_train.reshape(X_train.shape[0], 784)
X_train = X_train.astype('float64')
X_train = X_train / 255

X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255

#print(X_train[0])

# 클래스 값 확인
print("class : %d " % (Y_class_train[0]))

# 바이너리화 과정
Y_train = np_utils.to_categorical(Y_class_train, 10)
Y_test = np_utils.to_categorical(Y_class_test, 10)

print(Y_train[0])

```

+ 딥러닝 기본 프레임 만들기

책 내용을 기준으로 60000개의 학급셋과 10000개의 테스트셋을 불러와

속성 값을 지닌 X, 클래스 값을 지닌 Y로 구분하는 작업을 한다.

학습셋의 정확도 대신 학습셋의 오차를 그래프로 표현하면

학습셋의 오차는 1에서 학습셋의 정확도를 뺸 값입니다. 좀 더 세밀한 변화를 볼 수 있다.

***

```python
#-*- coding: utf-8 -*-

from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint,EarlyStopping

import matplotlib.pyplot as plt
import numpy
import os
import tensorflow as tf

# seed 값 설정
seed = 0
numpy.random.seed(seed)
tf.random.set_seed(3)

# MNIST 데이터 불러오기
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

X_train = X_train.reshape(X_train.shape[0], 784).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], 784).astype('float32') / 255

Y_train = np_utils.to_categorical(Y_train, 10)
Y_test = np_utils.to_categorical(Y_test, 10)

# 모델 프레임 설정
model = Sequential()
model.add(Dense(512, input_dim=784, activation='relu'))
model.add(Dense(10, activation='softmax'))

# 모델 실행 환경 설정
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# 모델 최적화 설정
MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
    os.mkdir(MODEL_DIR)

modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)

# 모델의 실행
history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])

# 테스트 정확도 출력
print("\n Test Accuracy: %.4f" % (model.evaluate(X_test, Y_test)[1]))

# 테스트 셋의 오차
y_vloss = history.history['val_loss']

# 학습셋의 오차
y_loss = history.history['loss']

# 그래프로 표현
x_len = numpy.arange(len(y_loss))
plt.plot(x_len, y_vloss, marker='.', c="red", label='Testset_loss')
plt.plot(x_len, y_loss, marker='.', c="blue", label='Trainset_loss')

# 그래프에 그리드를 주고 레이블을 표시
plt.legend(loc='upper right')
# plt.axis([0, 20, 0, 0.35])
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()


```

***

+ 더 깊은 딥러닝 

딥러닝의 기본 모델

<img width="81" alt="image" src="https://user-images.githubusercontent.com/101916929/220317396-6929620b-8cf4-4bad-b9a8-1281dbc76d89.png">

프로젝트에 맞춰서 어떤 옵션을 더하고 어떤 층을 추가하느냐에 따라 성능이 좋아질 수 있다.

딥러닝 프레임에 이미지 인식 분야에서 강력한 성능을 보이는 컨볼루션 신경망을 알아보자.

***

+ 컨볼루션 신경망(CNN)

컨볼루션 신경망은 입력된 이미지에서 다시 한번 특징을 추출하기 위해 커널을 도입하는 기법이다.


<img width="104" alt="image" src="https://user-images.githubusercontent.com/101916929/220318504-8e942c35-ee68-432a-8fe1-8c8538b2305e.png">

<img width="56" alt="image" src="https://user-images.githubusercontent.com/101916929/220318570-a8324b9e-92ae-4209-b857-32b7d32f95be.png">

<img width="95" alt="image" src="https://user-images.githubusercontent.com/101916929/220318605-880bff0c-1b29-46a4-9917-fe3d6e474822.png">


위와 같이 2x2커널을 준비하고 가중치의 값을 곱해준다.



<img width="275" alt="image" src="https://user-iages.githubusercontent.com/101916929/220318768-593c99f9-9443-42d8-8c1c-88dc1a99828d.png">


커널을 옮겨가면 가중치를 곱한 뒤 아래와 같이 결과를 정리 할 수 있다.

<img width="70" alt="image" src="https://user-images.githubusercontent.com/101916929/220318929-a1d850b0-a679-429f-8a63-500623321d22.png">


컨볼루션 층을 추가한 도식을 그려보면 다음과 같다.

<img width="220" alt="image" src="https://user-images.githubusercontent.com/101916929/220319144-d2cd1053-3561-4717-bb9f-deaefbf51f99.png">

***

+맥스풀링

앞서 구현한 컨볼루션 층을 통해 이미지 특징을 도출하였다. 하지만 그 결과가 여전히 크고 복잡하면 이를 다시 한번 축소해야 합니다.

이 과정을 풀링 또는 서브 샘플링이라고 한다.

풀링 기법에는 정해진 구역 안에서 최댓값을 뽑아내는 맥스 풀링과 평균값을 뽑아내는 평균 풀링이 있다.

<img width="101" alt="image" src="https://user-images.githubusercontent.com/101916929/220320234-6ad5b659-e634-463b-8d74-eb2295c513c6.png">

위 그림에서 맥스 쿨링을 적용하면

<img width="97" alt="image" src="https://user-images.githubusercontent.com/101916929/220320410-fa7ed6d0-a1c0-4135-a775-76ead0df28b4.png">

그리고 각 구역에서 가장 큰 값을 추출합니다.

<img width="63" alt="image" src="https://user-images.githubusercontent.com/101916929/220320648-e61a3628-15c8-4ce6-bddc-57f78cd04f25.png">


맥스 풀링 층을 추가한 모습을 도식으로 나타내면

<img width="221" alt="image" src="https://user-images.githubusercontent.com/101916929/220320974-7f145ac6-8279-4a73-9c21-02816f07851b.png">


+ 컨볼루션 신경망 실행하기

지금까지 살펴본 내용을 코드로 작성하면

MNIST 손글씨 인식하기: 컨볼루션 신경망 적용
```python
#-*- coding: utf-8 -*-

from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.callbacks import ModelCheckpoint,EarlyStopping

import matplotlib.pyplot as plt
import numpy
import os
import tensorflow as tf

# seed 값 설정
seed = 0
numpy.random.seed(seed)
tf.random.set_seed(3)

# 데이터 불러오기

(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255
Y_train = np_utils.to_categorical(Y_train)
Y_test = np_utils.to_categorical(Y_test)

# 컨볼루션 신경망의 설정
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128,  activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# 모델 최적화 설정
MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
    os.mkdir(MODEL_DIR)

modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)

# 모델의 실행
history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])

# 테스트 정확도 출력
print("\n Test Accuracy: %.4f" % (model.evaluate(X_test, Y_test)[1]))

# 테스트 셋의 오차
y_vloss = history.history['val_loss']

# 학습셋의 오차
y_loss = history.history['loss']

# 그래프로 표현
x_len = numpy.arange(len(y_loss))
plt.plot(x_len, y_vloss, marker='.', c="red", label='Testset_loss')
plt.plot(x_len, y_loss, marker='.', c="blue", label='Trainset_loss')

# 그래프에 그리드를 주고 레이블을 표시
plt.legend(loc='upper right')
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

```

<img width="258" alt="image" src="https://user-images.githubusercontent.com/101916929/220321828-67c0ae1c-b2fe-4d00-a02b-ab4058e380c0.png">

99.28%가 나온다 100%를 이루지 못한 이유는 테스트셋에 확인 할 수 없는 글씨가 있기 때문에

우리가 만든 딥러닝 모델은 이미 사람과 비슷하거나 뛰어넘는 인식률을 보여준다.





